
@article{bates2015,
  title = {Fitting {{Linear Mixed}}-{{Effects Models Using}} Lme4},
  author = {Bates, Douglas and M{\"a}chler, Martin and Bolker, Ben and Walker, Steve},
  year = {2015},
  volume = {67},
  issn = {1548-7660},
  doi = {10.18637/jss.v067.i01},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@misc{bengtsson2019,
  title = {Future: {{Unified}} Parallel and Distributed Processing in r for Everyone},
  author = {Bengtsson, Henrik},
  year = {2019}
}

@article{burkner2017,
  title = {Brms: {{An R}} Package for {{Bayesian}} Multilevel Models Using {{Stan}}},
  shorttitle = {Brms},
  author = {B{\"u}rkner, Paul-Christian},
  year = {2017},
  volume = {80},
  pages = {1--28},
  file = {D\:\\drive\\Documents\\zotero\\storage\\JHUEBTAA\\Bürkner - 2017 - brms An R package for Bayesian multilevel models .pdf},
  journal = {Journal of Statistical Software},
  number = {1}
}

@techreport{burkner2018,
  title = {Modeling {{Monotonic Effects}} of {{Ordinal Predictors}} in {{Bayesian Regression Models}}},
  author = {B{\"u}rkner, Paul - Christian and Charpentier, Emmanuel},
  year = {2018},
  month = nov,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/9qkhj},
  abstract = {Ordinal predictors are commonly used in regression models. They are often incorrectly treated as either nominal or metric, thus under- or overestimating the contained information. Such practices may lead to worse inference and predictions compared to methods which are specifically designed for this purpose. We propose a new method for modeling ordinal predictors that applies in situations in which it is reasonable to assume their effects to be monotonic. The parameterization of such monotonic effects is realized in terms of a scale parameter \$b\$ representing the direction and size of the effect and a simplex parameter \$\textbackslash{}zeta\$ modeling the normalized differences between categories. This ensures that predictions increase or decrease monotonically, while changes between adjacent categories may vary across categories. This formulation generalizes to interaction terms as well as multilevel structures. Monotonic effects may not only be applied to ordinal predictors, but also to  other discrete variables for which a monotonic relationship is plausible. In simulation studies, we show that the model is well calibrated and, in case of monotonicity, has similar or even better predictive performance than other approaches designed to handle ordinal predictors.  Using Stan, we developed a Bayesian estimation method for monotonic effects, which allows to incorporate prior information and to check the assumption of monotonicity. We have implemented this method in the R package brms, so that fitting monotonic effects in a fully Bayesian framework is now straightforward.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\ITJ79882\\Bürkner and Charpentier - 2018 - Modeling Monotonic Effects of Ordinal Predictors i.pdf},
  type = {Preprint}
}

@article{camos2008,
  title = {Discontinuity in the Enumeration of Sequentially Presented Auditory and Visual Stimuli},
  author = {Camos, Val{\'e}rie and Tillmann, Barbara},
  year = {2008},
  month = jun,
  volume = {107},
  pages = {1135--1143},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2007.11.002},
  abstract = {The seeking of discontinuity in enumeration was recently renewed because Cowan [Cowan, N. (2001). The magical number 4 in short-term memory: A reconsideration of mental storage capacity. Behavioral and Brain Sciences, 24, 87\textendash{}185; Cowan, N. (2005). Working memory capacity. Hove: Psychology Press] suggested that it allows evaluating the limit of the focus of attention, currently estimated at four items. A strong argument in favour of a general constraint of the cognitive system is that similar discontinuities should be observed in modalities different from the classic simultaneous presentation of visual objects. Recently, data were provided on tactile stimuli, but the authors diverged in their conclusion about the existence of such discontinuity [Gallace, A., Tan, H. Z., \& Spence, C. (2006). Numerosity judgments for tactile stimuli distributed over the body surface. Perception, 35(2), 247\textendash{}266; Riggs, K. J., Ferrand, L., Lancelin, D., Fryziel, L., Dumur, G., \& Simpson, A. (2006). Subitizing in tactile perception. Psychological Science, 17(4), 271\textendash{}272]. Following a similar rationale, our study aimed at evaluating discontinuity in the enumeration of auditory and visual stimuli presented sequentially. The clear and similar discontinuity observed in error rates, response times and given responses for both modalities favours the general capacity limit view, but also questions the size of this capacity, because the discontinuity occurred here at size 2. However, the masking of stimuli in sensory memory could not be entirely discarded.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\NWLB97HA\\Camos and Tillmann - 2008 - Discontinuity in the enumeration of sequentially p.pdf},
  journal = {Cognition},
  language = {en},
  number = {3}
}

@article{carlin1992,
  title = {Hierarchical {{Bayesian Analysis}} of {{Changepoint Problems}}},
  author = {Carlin, Bradley P. and Gelfand, Alan E. and Smith, Adrian F. M.},
  year = {1992},
  volume = {41},
  pages = {389--405},
  issn = {0035-9254},
  doi = {10.2307/2347570},
  abstract = {A general approach to hierarchical Bayes changepoint models is presented. In particular, desired marginal posterior densities are obtained utilizing the Gibbs sampler, an iterative Monte Carlo method. This approach avoids sophisticated analytic and numerical high dimensional integration procedures. We include an application to changing regressions, changing Poisson processes and changing Markov chains. Within these contexts we handle several previously inaccessible problems.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\GIP2FYHF\\Carlin et al. - 1992 - Hierarchical Bayesian Analysis of Changepoint Prob.pdf},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {2}
}

@article{carpenter2017,
  title = {Stan: {{A}} Probabilistic Programming Language},
  shorttitle = {Stan},
  author = {Carpenter, Bob and Gelman, Andrew and Hoffman, Matthew D. and Lee, Daniel and Goodrich, Ben and Betancourt, Michael and Brubaker, Marcus and Guo, Jiqiang and Li, Peter and Riddell, Allen},
  year = {2017},
  volume = {76},
  file = {D\:\\drive\\Documents\\zotero\\storage\\ZM5A2TBM\\Carpenter et al. - 2017 - Stan A probabilistic programming language.pdf},
  journal = {Journal of statistical software},
  number = {1}
}

@article{chen1997a,
  title = {Testing and {{Locating Variance Changepoints}} with {{Application}} to {{Stock Prices}}},
  author = {Chen, Jie and Gupta, A. K.},
  year = {1997},
  month = jun,
  volume = {92},
  pages = {739--747},
  issn = {0162-1459},
  doi = {10.1080/01621459.1997.10474026},
  abstract = {This article explores testing and locating multiple variance changepoints in a sequence of independent Gaussian random variables (assuming known and common mean). This type of problem is very common in applied economics and finance. A binary procedure combined with the Schwarz information criterion (SIC) is used to search all of the possible variance changepoints existing in the sequence. The simulated power of the proposed procedure is compared to that of the CUSUM procedure used by Incl{\'a}n and Tiao to cope with variance changepoints. The SIC and unbiased SIC for this problem are derived. To obtain the percentage points of the SIC criterion, the asymptotic null distribution of a function of the SIC is obtained, and then the approximate percentage points of the SIC are tabulated. Finally, the results are applied to the weekly stock prices. The unknown but common mean case is also outlined at the end.},
  journal = {Journal of the American Statistical Association},
  number = {438}
}

@article{colquhoun2014,
  title = {An Investigation of the False Discovery Rate and the Misinterpretation of P-Values},
  author = {Colquhoun, D.},
  year = {2014},
  month = nov,
  volume = {1},
  pages = {140216--140216},
  issn = {2054-5703},
  doi = {10.1098/rsos.140216},
  file = {D\:\\drive\\Documents\\zotero\\storage\\2CMJDBSB\\Colquhoun (2014) An investigation of the false discovery rate and the misenterpretation of p-values.pdf},
  journal = {Royal Society Open Science},
  language = {en},
  number = {3}
}

@article{conn2018,
  title = {A Guide to {{Bayesian}} Model Checking for Ecologists},
  author = {Conn, Paul B. and Johnson, Devin S. and Williams, Perry J. and Melin, Sharon R. and Hooten, Mevin B.},
  year = {2018},
  volume = {88},
  pages = {526--542},
  issn = {1557-7015},
  doi = {10.1002/ecm.1314},
  abstract = {Checking that models adequately represent data is an essential component of applied statistical inference. Ecologists increasingly use hierarchical Bayesian statistical models in their research. The appeal of this modeling paradigm is undeniable, as researchers can build and fit models that embody complex ecological processes while simultaneously accounting for observation error. However, ecologists tend to be less focused on checking model assumptions and assessing potential lack of fit when applying Bayesian methods than when applying more traditional modes of inference such as maximum likelihood. There are also multiple ways of assessing the fit of Bayesian models, each of which has strengths and weaknesses. For instance, Bayesian P values are relatively easy to compute, but are well known to be conservative, producing P values biased toward 0.5. Alternatively, lesser known approaches to model checking, such as prior predictive checks, cross-validation probability integral transforms, and pivot discrepancy measures may produce more accurate characterizations of goodness-of-fit but are not as well known to ecologists. In addition, a suite of visual and targeted diagnostics can be used to examine violations of different model assumptions and lack of fit at different levels of the modeling hierarchy, and to check for residual temporal or spatial autocorrelation. In this review, we synthesize existing literature to guide ecologists through the many available options for Bayesian model checking. We illustrate methods and procedures with several ecological case studies including (1) analysis of simulated spatiotemporal count data, (2) N-mixture models for estimating abundance of sea otters from an aircraft, and (3) hidden Markov modeling to describe attendance patterns of California sea lion mothers on a rookery. We find that commonly used procedures based on posterior predictive P values detect extreme model inadequacy, but often do not detect more subtle cases of lack of fit. Tests based on cross-validation and pivot discrepancy measures (including the ``sampled predictive P value'') appear to be better suited to model checking and to have better overall statistical performance. We conclude that model checking is necessary to ensure that scientific inference is well founded. As an essential component of scientific discovery, it should accompany most Bayesian analyses presented in the literature.},
  copyright = {Published 2018. This article is a U.S. Government work and is in the public domain in the USA.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\JFIQRHGE\\Conn et al. - 2018 - A guide to Bayesian model checking for ecologists.pdf},
  journal = {Ecological Monographs},
  language = {en},
  number = {4}
}

@article{cowan2000,
  title = {The Magical Number 4 in Short-Term Memory: {{A}} Reconsideration of Mental Storage Capacity},
  shorttitle = {The Magical Number 4 in Short-Term Memory},
  author = {Cowan, N.},
  year = {2000},
  volume = {24},
  pages = {87--114},
  file = {D\:\\drive\\Documents\\zotero\\storage\\FWHTCDQF\\Cowan (2000) - Magic 4 and responses.pdf},
  journal = {Behavioral and brain sciences},
  keywords = {K10,printed,read},
  lccn = {1359},
  note = {00000},
  number = {01}
}

@article{erdman2007,
  title = {Bcp: {{An R Package}} for {{Performing}} a {{Bayesian Analysis}} of {{Change Point Problems}}},
  shorttitle = {Bcp},
  author = {Erdman, Chandra and Emerson, John W.},
  year = {2007},
  month = dec,
  volume = {23},
  pages = {1--13},
  issn = {1548-7660},
  doi = {10.18637/jss.v023.i03},
  copyright = {Copyright (c) 2007 Chandra Erdman, John W. Emerson},
  file = {D\:\\drive\\Documents\\zotero\\storage\\FQVRJBNK\\Erdman and Emerson - 2007 - bcp An R Package for Performing a Bayesian Analys.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{fuller1981,
  title = {Properties of {{Predictors}} for {{Autoregressive Time Series}}},
  author = {Fuller, Wayne A. and Hasza, David P.},
  year = {1981},
  volume = {76},
  pages = {155--161},
  issn = {0162-1459},
  doi = {10.2307/2287061},
  abstract = {The prediction of the (n + s)th observation of the pth order autoregressive process is investigated. The mean square of the predictor error through terms of order n\textsuperscript{-1}, conditional on Y\textsubscript{n}, Y\textsubscript{n - 1}, {$\cdots$}, Y\textsubscript{n - p + 1}, is obtained for the stationary normal process. The mean squared error expression is similar to the usual regression formula for the variance of the predictor error. The usual regression formula for the estimated variance of a predictor error and its generalization to s-period prediction is shown to provide a consistent estimator of the mean squared error of the least squares predictor for both stationary and nonstationary processes.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\75FXX5ZH\\Fuller and Hasza - 1981 - Properties of Predictors for Autoregressive Time S.pdf},
  journal = {Journal of the American Statistical Association},
  number = {373}
}

@article{gabry2019,
  title = {Visualization in {{Bayesian}} Workflow},
  author = {Gabry, Jonah and Simpson, Daniel and Vehtari, Aki and Betancourt, Michael and Gelman, Andrew},
  year = {2019},
  volume = {182},
  pages = {389--402},
  issn = {1467-985X},
  doi = {10.1111/rssa.12378},
  abstract = {Bayesian data analysis is about more than just computing a posterior distribution, and Bayesian visualization is about more than trace plots of Markov chains. Practical Bayesian data analysis, like all data analysis, is an iterative process of model building, inference, model checking and evaluation, and model expansion. Visualization is helpful in each of these stages of the Bayesian workflow and it is indispensable when drawing inferences from the types of modern, high dimensional models that are used by applied researchers.},
  copyright = {\textcopyright{} 2019 Royal Statistical Society},
  file = {D\:\\drive\\Documents\\zotero\\storage\\UK7S3R88\\Gabry et al. - 2019 - Visualization in Bayesian workflow.pdf},
  journal = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  language = {en},
  number = {2}
}

@article{gelman1992,
  ids = {gelman1992},
  title = {Inference from Iterative Simulation Using Multiple Sequences},
  author = {Gelman, Andrew and Rubin, Donald B.},
  year = {1992},
  volume = {7},
  pages = {457--472},
  file = {D\:\\drive\\Documents\\zotero\\storage\\HMZMLUFS\\Gelman and Rubin - 1992 - Inference from Iterative Simulation Using Multiple.pdf},
  journal = {Statistical science},
  number = {4}
}

@article{gelman2013b,
  title = {Understanding Predictive Information Criteria for {{Bayesian}} Models},
  author = {Gelman, Andrew and Hwang, Jessica and Vehtari, Aki},
  year = {2013},
  month = jul,
  abstract = {We review the Akaike, deviance, and Watanabe-Akaike information criteria from a Bayesian perspective, where the goal is to estimate expected out-of-sample-prediction error using a biascorrected adjustment of within-sample error. We focus on the choices involved in setting up these measures, and we compare them in three simple examples, one theoretical and two applied. The contribution of this review is to put all these information criteria into a Bayesian predictive context and to better understand, through small examples, how these methods can apply in practice.},
  archivePrefix = {arXiv},
  eprint = {1307.5928},
  eprinttype = {arxiv},
  file = {D\:\\drive\\Documents\\zotero\\storage\\N69C6RA3\\Gelman et al. - 2013 - Understanding predictive information criteria for .pdf},
  journal = {arXiv:1307.5928 [stat]},
  primaryClass = {stat}
}

@article{gronau2018,
  title = {Bridgesampling: {{An R Package}} for {{Estimating Normalizing Constants}}},
  shorttitle = {Bridgesampling},
  author = {Gronau, Quentin F. and Singmann, Henrik and Wagenmakers, Eric-Jan},
  year = {2018},
  month = sep,
  abstract = {Statistical procedures such as Bayes factor model selection and Bayesian model averaging require the computation of normalizing constants (e.g., marginal likelihoods). These normalizing constants are notoriously difficult to obtain, as they usually involve high-dimensional integrals that cannot be solved analytically. Here we introduce an R package that uses bridge sampling (Meng \& Wong, 1996; Meng \& Schilling, 2002) to estimate normalizing constants in a generic and easy-to-use fashion. For models implemented in Stan, the estimation procedure is automatic. We illustrate the functionality of the package with three examples.},
  archivePrefix = {arXiv},
  eprint = {1710.08162},
  eprinttype = {arxiv},
  file = {D\:\\drive\\Documents\\zotero\\storage\\H7WXXZKN\\Gronau et al. - 2018 - bridgesampling An R Package for Estimating Normal.pdf},
  journal = {arXiv:1710.08162 [stat]},
  primaryClass = {stat}
}

@misc{gronau2019,
  title = {Bridgesampling: {{Bridge}} Sampling for Marginal Likelihoods and Bayes Factors},
  author = {Gronau, Quentin F. and Singmann, Henrik},
  year = {2019}
}

@article{gronau2019a,
  title = {Limitations of {{Bayesian Leave}}-{{One}}-{{Out Cross}}-{{Validation}} for {{Model Selection}}},
  author = {Gronau, Quentin F. and Wagenmakers, Eric-Jan},
  year = {2019},
  month = mar,
  volume = {2},
  pages = {1--11},
  issn = {2522-087X},
  doi = {10.1007/s42113-018-0011-7},
  abstract = {Cross-validation (CV) is increasingly popular as a generic method to adjudicate between mathematical models of cognition and behavior. In order to measure model generalizability, CV quantifies out-of-sample predictive performance, and the CV preference goes to the model that predicted the out-of-sample data best. The advantages of CV include theoretic simplicity and practical feasibility. Despite its prominence, however, the limitations of CV are often underappreciated. Here, we demonstrate the limitations of a particular form of CV\textemdash{}Bayesian leave-one-out cross-validation or LOO\textemdash{}with three concrete examples. In each example, a data set of infinite size is perfectly in line with the predictions of a simple model (i.e., a general law or invariance). Nevertheless, LOO shows bounded and relatively modest support for the simple model. We conclude that CV is not a panacea for model selection.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\PM2WTCVA\\Gronau and Wagenmakers - 2019 - Limitations of Bayesian Leave-One-Out Cross-Valida.pdf},
  journal = {Computational Brain \& Behavior},
  language = {en},
  number = {1}
}

@misc{haynes2019,
  title = {Changepoint.Np: {{Methods}} for Nonparametric Changepoint Detection},
  author = {Haynes, Kaylea and Killick, Rebecca},
  year = {2019}
}

@article{james2015,
  title = {Ecp: {{An R Package}} for {{Nonparametric Multiple Change Point Analysis}} of {{Multivariate Data}}},
  shorttitle = {Ecp},
  author = {James, Nicholas A. and Matteson, David S.},
  year = {2015},
  month = jan,
  volume = {62},
  pages = {1--25},
  issn = {1548-7660},
  doi = {10.18637/jss.v062.i07},
  copyright = {Copyright (c) 2013 Nicholas A. James, David S. Matteson},
  file = {D\:\\drive\\Documents\\zotero\\storage\\ZTCUMVIF\\James and Matteson - 2015 - ecp An R Package for Nonparametric Multiple Chang.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@techreport{jensen2013,
  title = {Closed-{{Form Estimation}} of {{Multiple Change}}-{{Point Models}}},
  author = {Jensen, Greg},
  year = {2013},
  month = dec,
  institution = {{PeerJ PrePrints}},
  doi = {10.7287/peerj.preprints.90v3},
  abstract = {Identifying discontinuities (or change-points) in otherwise stationary time series is a powerful analytic tool. This paper outlines a general strategy for identifying an unknown number of change-points using elementary principles of Bayesian statistics. Using a strategy of binary partitioning by marginal likelihood, a time series is recursively subdivided on the basis of whether additional subdivisions (and thus increased model complexity) yield a justified improvement in the marginal model likelihood. When this approach is combined with the use of conjugate priors, it yields the Conjugate Partitioned Recursion (CPR) algorithm, which identifies change-points without computationally intensive numerical integration. Using the CPR algorithm, methods are described for specifying change-point models drawn from a host of familiar distributions, both discrete (binomial, geometric, Poisson) and continuous (exponential, Gaussian, uniform, and multiple linear regression), as well as multivariate distributions (multinomial, multivariate normal, and multivariate linear regression). Methods by which the CPR algorithm could be extended or modified are discussed, and several detailed applications to data published in psychology and biomedical engineering are described.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\VWYX9YYP\\Jensen - 2013 - Closed-Form Estimation of Multiple Change-Point Mo.pdf},
  language = {en},
  type = {Preprint}
}

@article{killick2014,
  title = {Changepoint: {{An R Package}} for {{Changepoint Analysis}}},
  shorttitle = {Changepoint},
  author = {Killick, Rebecca and Eckley, Idris A.},
  year = {2014},
  month = jun,
  volume = {58},
  pages = {1--19},
  issn = {1548-7660},
  doi = {10.18637/jss.v058.i03},
  copyright = {Copyright (c) 2013 Rebecca Killick, Idris A. Eckley},
  file = {D\:\\drive\\Documents\\zotero\\storage\\2AR9I6SJ\\Killick and Eckley - 2014 - changepoint An R Package for Changepoint Analysis.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@misc{killick2018,
  title = {{{EnvCpt}}: {{Detection}} of Structural Changes in Climate and Environment Time Series},
  author = {Killick, Rebecca and Beaulieu, Claudie and Taylor, Simon and Hullait, Harjit},
  year = {2018}
}

@article{knuth1992,
  title = {Two {{Notes}} on {{Notation}}},
  author = {Knuth, Donald E.},
  year = {1992},
  volume = {99},
  pages = {403--422},
  issn = {0002-9890},
  doi = {10.2307/2325085},
  file = {D\:\\drive\\Documents\\zotero\\storage\\XJPA48GR\\Knuth - 1992 - Two notes on notation.pdf},
  journal = {The American Mathematical Monthly},
  number = {5}
}

@misc{korkas2018,
  title = {Wbsts: {{Multiple}} Change-Point Detection for Nonstationary Time Series},
  author = {Korkas, Karolos and Fryzlewicz, Piotr},
  year = {2018}
}

@article{kruschke2011,
  title = {Bayesian Assessment of Null Values via Parameter Estimation and Model Comparison},
  author = {Kruschke, John K.},
  year = {2011},
  volume = {6},
  pages = {299--312},
  file = {D\:\\drive\\Documents\\zotero\\storage\\WGFG7X4P\\Kruschke (2011) bayesian parameter estimation or model selection - against NHST.pdf},
  journal = {Perspectives on Psychological Science},
  keywords = {K10,read},
  number = {3}
}

@article{kruschke2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  volume = {25},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\NJ7965PR\\Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf},
  journal = {Psychonomic Bulletin \& Review},
  language = {en},
  number = {1}
}

@article{lee2003,
  title = {The {{Cusum Test}} for {{Parameter Change}} in {{Time Series Models}}},
  author = {Lee, Sangyeol and Ha, Jeongcheol and Na, Okyoung and Na, Seongryong},
  year = {2003},
  volume = {30},
  pages = {781--796},
  issn = {1467-9469},
  doi = {10.1111/1467-9469.00364},
  abstract = {Abstract. In this paper, we consider the problem of testing for parameter changes in time series models based on a cusum test. Although the test procedure is well established for the mean and variance in time series models, a general parameter case has not been discussed in the literature. Therefore, here we develop a cusum test for parameter change in a more general framework. As an example, we consider the change of the parameters in a random coeefficient autoregressive (1) model and that of the autocovariances of a linear process. Simulation results are reported for illustration.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\RAI5LQ3C\\Lee et al. - The Cusum Test for Parameter Change in Time Series.pdf},
  journal = {Scandinavian Journal of Statistics},
  language = {en},
  number = {4}
}

@article{leibovich-raveh2018,
  title = {A {{New Method}} for {{Calculating Individual Subitizing Ranges}}},
  author = {{Leibovich-Raveh}, Tali and Lewis, Daniel Jacob and Kadhim, Saja Al-Rubaiey and Ansari, Daniel},
  year = {2018},
  month = sep,
  volume = {4},
  pages = {429--447},
  issn = {2363-8761},
  doi = {10.5964/jnc.v4i2.74},
  abstract = {A large body of research has shown that human adults are fast and accurate at enumerating arrays of \textasciitilde{}1-4 items. This phenomenon has been called subitizing. Above this range, enumeration is slower and less accurate. The subitizing range has been related to individual differences in variables such as mathematical abilities, working memory, etc. The two most common methods for calculating subitizing range today \textendash{} bilinear fit and sigmoid fit \textendash{} have their strengths and weaknesses. By combining these two methods, we overcome their biggest limitations and come up with a novel way for calculating Individual Subitizing Range (ISR). This paper introduces this new method as well as empirical studies designed to test the new method. We replicated classic effects from the literature and obtain a high correlation with the sigmoid fit method. This paper includes a Matlab code for easy calculation of ISR as well as a ready-to-use experimental file for testing ISR. We hope that these tools would be of use to researchers studying individual differences in the subitizing range.},
  copyright = {Copyright (c) 2018 Leibovich-Raveh; Lewis; Al-Rubaiey Kadhim; Ansari},
  file = {D\:\\drive\\Documents\\zotero\\storage\\R6LK2JD2\\Leibovich-Raveh et al. - 2018 - A New Method for Calculating Individual Subitizing.pdf},
  journal = {Journal of Numerical Cognition},
  language = {en},
  number = {2}
}

@misc{li2018,
  title = {{{TSMCP}}: {{Fast}} Two Stage Multiple Change Point Detection},
  author = {Li, Yaguang and Jin, Baisuo},
  year = {2018}
}

@article{lindelov2018,
  title = {Using Performance Discontinuities to Estimate Individual {{Working}}-{{Memory Capacities}} in Serial Recall Tasks},
  author = {Lindel{\o}v, Jonas},
  year = {2018},
  month = sep,
  volume = {18},
  pages = {698--698},
  issn = {1534-7362},
  doi = {10.1167/18.10.698},
  journal = {Journal of Vision},
  language = {en},
  number = {10}
}

@book{lunn2012,
  title = {The {{BUGS}} Book: {{A}} Practical Introduction to {{Bayesian}} Analysis},
  shorttitle = {The {{BUGS}} Book},
  author = {Lunn, David and Jackson, Chris and Best, Nicky and Spiegelhalter, David and Thomas, Andrew},
  year = {2012},
  publisher = {{Chapman and Hall/CRC}},
  file = {D\:\\drive\\Documents\\zotero\\storage\\YT3CSRWC\\Lunn et al. - 2012 - The BUGS book A practical introduction to Bayesia.pdf}
}

@article{martino2017,
  title = {Effective {{Sample Size}} for {{Importance Sampling}} Based on Discrepancy Measures},
  author = {Martino, L. and Elvira, V. and Louzada, F.},
  year = {2017},
  month = feb,
  volume = {131},
  pages = {386--401},
  issn = {01651684},
  doi = {10.1016/j.sigpro.2016.08.025},
  abstract = {The Effective Sample Size (ESS) is an important measure of efficiency of Monte Carlo methods such as Markov Chain Monte Carlo (MCMC) and Importance Sampling (IS) techniques. In the IS context, an approximation ESS of the theoretical ESS definition is widely applied, involving the inverse of the sum of the squares of the normalized importance weights. This formula, ESS, has become an essential piece within Sequential Monte Carlo (SMC) methods, to assess the convenience of a resampling step. From another perspective, the expression ESS is related to the Euclidean distance between the probability mass described by the normalized weights and the discrete uniform probability mass function (pmf). In this work, we derive other possible ESS functions based on different discrepancy measures between these two pmfs. Several examples are provided involving, for instance, the geometric mean of the weights, the discrete entropy (including the perplexity measure, already proposed in literature) and the Gini coefficient among others. We list five theoretical requirements which a generic ESS function should satisfy, allowing us to classify different ESS measures. We also compare the most promising ones by means of numerical simulations.},
  archivePrefix = {arXiv},
  eprint = {1602.03572},
  eprinttype = {arxiv},
  file = {D\:\\drive\\Documents\\zotero\\storage\\X5KE2WNU\\Martino et al. - 2017 - Effective Sample Size for Importance Sampling base.pdf},
  journal = {Signal Processing},
  language = {en}
}

@article{muggeo2008,
  title = {Segmented: An {{R}} Package to Fit Regression Models with Broken-Line Relationships},
  shorttitle = {Segmented},
  author = {Muggeo, Vito MR},
  year = {2008},
  volume = {8},
  pages = {20--25},
  file = {D\:\\drive\\Documents\\zotero\\storage\\EVKHW6HX\\Muggeo - 2008 - Segmented an R package to fit regression models w.pdf},
  journal = {R news},
  number = {1}
}

@article{muggeo2017,
  title = {Interval Estimation for the Breakpoint in Segmented Regression: A Smoothed Score-Based Approach},
  shorttitle = {Interval Estimation for the Breakpoint in Segmented Regression},
  author = {Muggeo, Vito M. R.},
  year = {2017},
  volume = {59},
  pages = {311--322},
  issn = {1467-842X},
  doi = {10.1111/anzs.12200},
  abstract = {This paper is concerned with interval estimation for the breakpoint parameter in segmented regression. We present score-type confidence intervals derived from the score statistic itself and from the recently proposed gradient statistic. Due to lack of regularity conditions of the score, non-smoothness and non-monotonicity, naive application of the score-based statistics is unfeasible and we propose to exploit the smoothed score obtained via induced smoothing. We compare our proposals with the traditional methods based on the Wald and the likelihood ratio statistics via simulations and an analysis of a real dataset: results show that the smoothed score-like statistics perform in practice somewhat better than competitors, even when the model is not correctly specified.},
  copyright = {\textcopyright{} 2017 Australian Statistical Publishing Association Inc. Published by John Wiley \& Sons Australia Pty Ltd.},
  journal = {Australian \& New Zealand Journal of Statistics},
  language = {en},
  number = {3}
}

@article{munafo2017,
  title = {A Manifesto for Reproducible Science},
  author = {Munaf{\`o}, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and du Sert, Nathalie Percie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
  year = {2017},
  month = jan,
  volume = {1},
  pages = {1--9},
  issn = {2397-3374},
  doi = {10.1038/s41562-016-0021},
  abstract = {Leading voices in the reproducibility landscape call for the adoption of measures to optimize key elements of the scientific process.},
  copyright = {2017 Macmillan Publishers Limited},
  file = {D\:\\drive\\Documents\\zotero\\storage\\CRGJBUB8\\Munafò et al. - 2017 - A manifesto for reproducible science.pdf},
  journal = {Nature Human Behaviour},
  language = {en},
  number = {1}
}

@article{page1954,
  title = {Continuous {{Inspection Schemes}}},
  author = {Page, E. S.},
  year = {1954},
  volume = {41},
  pages = {100--115},
  issn = {0006-3444},
  doi = {10.2307/2333009},
  file = {D\:\\drive\\Documents\\zotero\\storage\\Y5QS6NAF\\Page - 1954 - Continuous Inspection Schemes.pdf},
  journal = {Biometrika},
  number = {1/2}
}

@article{pesti2009,
  title = {A Comparison of Methods to Estimate Nutritional Requirements from Experimental Data},
  author = {Pesti, Dr G. M. and Vedenov, D. and Cason, J. A. and Billard, L.},
  year = {2009},
  month = jan,
  volume = {50},
  pages = {16--32},
  issn = {0007-1668},
  doi = {10.1080/00071660802530639},
  abstract = {1. Research papers use a variety of methods for evaluating experiments designed to determine nutritional requirements of poultry. Growth trials result in a set of ordered pairs of data. Often, point-by-point comparisons are made between treatments using analysis of variance. This approach ignores that response variables (body weight, feed efficiency, bone ash, etc.) are continuous rather than discrete. Point-by-point analyses harvest much less than the total amount of information from the data. Regression models are more effective at gleaning information from data, but the concept of ``requirements'' is poorly defined by many regression models. 2. Response data from a study of the lysine requirements of young broilers was used to compare methods of determining requirements. In this study, multiple range tests were compared with quadratic polynomials (QP), broken line models with linear (BLL) or quadratic (BLQ) ascending portions, the saturation kinetics model (SK) a logistic model (LM) and a compartmental (CM) model. 3. The sum of total residuals squared was used to compare the models. The SK and LM were the best fit models, followed by the CM, BLL, BLQ, and QP models. A plot of the residuals versus nutrient intake showed clearly that the BLQ and SK models fitted the data best in the important region where the ascending portion meets the plateau. 4. The BLQ model clearly defines the technical concept of nutritional requirements as typically defined by nutritionists. However, the SK, LM and CM models better depict the relationship typically defined by economists as the ``law of diminishing marginal productivity''. The SK model was used to demonstrate how the law of diminishing marginal productivity can be applied to poultry nutrition, and how the ``most economical feeding level'' may replace the concept of ``requirements''.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\T289TBB4\\Pesti et al. - 2009 - A comparison of methods to estimate nutritional re.pdf},
  journal = {British Poultry Science},
  number = {1},
  pmid = {19234926}
}

@inproceedings{plummer2003,
  title = {{{JAGS}}: {{A}} Program for Analysis of {{Bayesian}} Graphical Models Using {{Gibbs}} Sampling},
  shorttitle = {{{JAGS}}},
  booktitle = {Proceedings of the 3rd International Workshop on Distributed Statistical Computing},
  author = {Plummer, Martyn},
  year = {2003},
  volume = {124},
  pages = {125},
  publisher = {{Vienna, Austria}},
  file = {D\:\\drive\\Documents\\zotero\\storage\\WDG4ZDIN\\Plummer - 2003 - JAGS A program for analysis of Bayesian graphical.pdf}
}

@article{plummer2006,
  title = {{{CODA}}: Convergence Diagnosis and Output Analysis for {{MCMC}}},
  shorttitle = {{{CODA}}},
  author = {Plummer, Martyn and Best, Nicky and Cowles, Kate and Vines, Karen},
  year = {2006},
  volume = {6},
  pages = {7--11},
  journal = {R news},
  number = {1}
}

@article{raftery1986,
  title = {Bayesian Analysis of a {{Poisson}} Process with a Change-Point},
  author = {Raftery, Adrian Elmes and Akman, V. E.},
  year = {1986},
  volume = {73},
  pages = {85--89},
  file = {D\:\\drive\\Documents\\zotero\\storage\\NBT33ZER\\Raftery and Akman - 1986 - Bayesian analysis of a Poisson process with a chan.pdf},
  journal = {Biometrika},
  number = {1}
}

@book{rcoreteam2019,
  title = {R: {{A}} Language and Environment for Statistical Computing},
  author = {{R Core Team}},
  year = {2019},
  address = {{Vienna, Austria}},
  organization = {{R Foundation for Statistical Computing}}
}

@article{ross2015,
  title = {Parametric and {{Nonparametric Sequential Change Detection}} in {{R}}: {{The}} Cpm {{Package}}},
  shorttitle = {Parametric and {{Nonparametric Sequential Change Detection}} in {{R}}},
  author = {Ross, Gordon J.},
  year = {2015},
  month = aug,
  volume = {66},
  pages = {1--20},
  issn = {1548-7660},
  doi = {10.18637/jss.v066.i03},
  copyright = {Copyright (c) 2012  Gordon J. Ross},
  file = {D\:\\drive\\Documents\\zotero\\storage\\GG7E5AZM\\Ross - 2015 - Parametric and Nonparametric Sequential Change Det.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{stephens1994,
  title = {Bayesian {{Retrospective Multiple}}-{{Changepoint Identification}}},
  author = {Stephens, D. A.},
  year = {1994},
  volume = {43},
  pages = {159--178},
  issn = {0035-9254},
  doi = {10.2307/2986119},
  abstract = {Changepoint identification is important in many data analysis problems, such as industrial control and medical diagnosis--given a data sequence, we wish to make inference about the location of one or more points of the sequence at which there is a change in the model or parameters driving the system. For long data sequences, however, analysis (especially in the multiple-changepoint case) can become computationally prohibitive, and for complex non-linear models analytical and conventional numerical techniques are infeasible. We discuss the use of a sampling-based technique, the Gibbs sampler, in multiple-changepoint problems and demonstrate how it can be used to reduce the computational load involved considerably. Also, often it is reasonable to presume that the data model itself is continuous with respect to time, i.e. continuous at the changepoints. This necessitates a continuous parameter representation of the changepoint problem, which also leads to computational difficulties. We demonstrate how inferences can be made readily in such problems by using the Gibbs sampler. We study three examples: a simple discrete two-changepoint problem based on a binomial data model; a continuous switching linear regression problem; a continuous, non-linear, multiple-changepoint problem.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\KZVD6BUN\\Stephens - 1994 - Bayesian Retrospective Multiple-Changepoint Identi.pdf},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {1}
}

@article{vehtari2017,
  title = {Practical {{Bayesian}} Model Evaluation Using Leave-One-out Cross-Validation and {{WAIC}}},
  author = {Vehtari, Aki and Gelman, Andrew and Gabry, Jonah},
  year = {2017},
  month = sep,
  volume = {27},
  pages = {1413--1432},
  issn = {1573-1375},
  doi = {10.1007/s11222-016-9696-4},
  abstract = {Leave-one-out cross-validation (LOO) and the widely applicable information criterion (WAIC) are methods for estimating pointwise out-of-sample prediction accuracy from a fitted Bayesian model using the log-likelihood evaluated at the posterior simulations of the parameter values. LOO and WAIC have various advantages over simpler estimates of predictive error such as AIC and DIC but are less used in practice because they involve additional computational steps. Here we lay out fast and stable computations for LOO and WAIC that can be performed using existing simulation draws. We introduce an efficient computation of LOO using Pareto-smoothed importance sampling (PSIS), a new procedure for regularizing importance weights. Although WAIC is asymptotically equal to LOO, we demonstrate that PSIS-LOO is more robust in the finite case with weak priors or influential observations. As a byproduct of our calculations, we also obtain approximate standard errors for estimated predictive errors and for comparison of predictive errors between two models. We implement the computations in an R package called loo and demonstrate using models fit with the Bayesian inference package Stan.},
  file = {D\:\\drive\\Documents\\zotero\\storage\\CSES5F67\\Vehtari m.fl. - 2017 - Practical Bayesian model evaluation using leave-on.pdf},
  journal = {Statistics and Computing},
  language = {en},
  number = {5}
}

@article{verdinelli1995,
  title = {Computing {{Bayes Factors Using}} a {{Generalization}} of the {{Savage}}-{{Dickey Density Ratio}}},
  author = {Verdinelli, Isabella and Wasserman, Larry},
  year = {1995},
  month = jun,
  volume = {90},
  pages = {614--618},
  issn = {0162-1459},
  doi = {10.1080/01621459.1995.10476554},
  abstract = {We present a simple method for computing Bayes factors. The method derives from observing that in general, a Bayes factor can be written as the product of a quantity called the Savage-Dickey density ratio and a correction factor; both terms are easily estimated from posterior simulation. In some cases it is possible to do these computations without ever evaluating the likelihood.},
  journal = {Journal of the American Statistical Association},
  number = {430}
}

@article{zeileis2002,
  title = {Strucchange: {{An R Package}} for {{Testing}} for {{Structural Change}} in {{Linear Regression Models}}},
  shorttitle = {Strucchange},
  author = {Zeileis, Achim and Leisch, Friedrich and Hornik, Kurt and Kleiber, Christian},
  year = {2002},
  month = jan,
  volume = {7},
  pages = {1--38},
  issn = {1548-7660},
  doi = {10.18637/jss.v007.i02},
  copyright = {Copyright (c) 2001 Achim Zeileis, Friedrich Leisch, Kurt Hornik, Christian Kleiber},
  file = {D\:\\drive\\Documents\\zotero\\storage\\GGA2ENQ4\\Zeileis et al. - 2002 - strucchange An R Package for Testing for Structur.pdf},
  journal = {Journal of Statistical Software},
  language = {en},
  number = {1}
}

@article{zeileis2003,
  title = {Testing and Dating of Structural Changes in Practice},
  author = {Zeileis, Achim and Kleiber, Christian and Kr{\"a}mer, Walter and Hornik, Kurt},
  year = {2003},
  volume = {44},
  pages = {109--123},
  file = {D\:\\drive\\Documents\\zotero\\storage\\7GXHZS5W\\Zeileis et al. - 2003 - Testing and dating of structural changes in practi.pdf},
  journal = {Computational Statistics \& Data Analysis},
  number = {1-2}
}


